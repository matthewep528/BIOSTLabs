---
title: "M4 Lab"
author: "Matthew Præstgaard"
date: "Spring 2024"
output:
  rmdformats::downcute:
    self_contained: true
    default_style: "dark"
    downcute_theme: "default"
    code_folding: "show"
  svglite:
    fig.retina: 2
---

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
```




# Lab Setup

## R packages

Load necessary packages. 

```{r, message = FALSE}
library(tidyverse)
library(readxl)
library(here)
library(car)
library(pROC)
library(glmnet)
library(glmtoolbox)
library(nnet)
library(jtools)
library(lintr)

lint_dir(path = here("BIOSTLabs", ".lintr"))
```

## Data management

The following data description comes from https://www.causeweb.org/tshs/hot-flashes/: 

Menopause heralds a complex array of hormonal and physiologic changes, the most common of which is the feverish discomfort of hot flashes and often accompanied by sweating, chills and anxiety. The Mayo Clinic defines a hot flash as the “sudden feeling of warmth in the upper body which is usually most intense over the face, neck and chest”. Among women in the menopausal transition, hot flashes typically occur daily, are between 2-5 minutes duration, and can be expected to persist for more than 7 years  Variations in hot flash experiences during the menopausal transition among different populations have been observed but are incompletely understood.

The aim of this lab is to explore race differences in self-reported hot flashes while considering other factors such as demographic information, BMI, reproductive hormone levels, and smoking.


```{r}

# read in the data
# make age group a factor variable (otherwise it will read as numeric in regression models)

hflash <- read_xlsx(here("Lab5", "hflash.xlsx")) %>%
    mutate(
        AgeGroup = factor(ageg - 1), # making dummy variable for age group with levels 0-3
        aagrp = factor(aagrp), # changing categorical variables to factors to be safe
        edu = factor(edu),
        d1 = factor(d1),
        f1a = factor(f1a),
        hotflash = factor(hotflash),
        bmi30 = factor(bmi30)
    ) %>%
    drop_na()

kable(head(hflash))

```

# Data Analysis

## 1. Simple logistic regression model

__Fit a logistic regression model with race as the only predictor and self-reported hot flashes as the outcome. Is race significantly associated with the odds of self-reported hot flashes? Interpret the exponentiated coefficient for race in this model.__

```{r}

# fit logistic regression model with just race
glmRace <- glm(hotflash ~ aagrp, data = hflash, family = binomial(link = "logit"))
# print model output
summ(glmRace)

# exponentiated coefficient
exp(coef(glmRace))

```

Interpretation:

## 2. Multiple logistic regression model

__Fit a logistic regression model for self-reported hot flashes (outcome) using race, age group,__
__education, smoking status, pcs12, obesity status, estradiol, FSH, LH, testosterone, and__
__dehydroepiandrosterone sulfate as predictors. What happens to the estimated association between__
__race and log-odds of self-reported hot flashes after adjusting for these variables?__

```{r}

# fit logistic regression model with all predictors mentioned (not d1 (history of menopausal symptoms) or pt (patient id))
glmFull <- glm(hotflash ~ aagrp + AgeGroup + edu + f1a + pcs12 + bmi30 + estra + fsh + lh + testo + dheas, data = hflash, family = binomial(link = "logit"))

# print output
summ(glmFull)
```

Response: 

## 3. Sensitivity and specificity

__Use the predicted probabilities from the fully adjusted model from part 2 to calculate the sensitivity__
__and specificity using the thresholds 0.25, 0.5, and 0.75 to determine the predicted classes of each observation. What happens as you increase the threshold?__

```{r}

y <- glmFull$y
phat <- predict(glmFull, type = "response")

# threshold 1 (0.25)
thresh1 <- 0.25

yhat1 <- as.numeric(phat > thresh1)

data.frame(predicted = yhat1, observed = y) %>%
  xtabs(~ predicted + observed, data = .)

# threshold 2 (0.5)
thresh2 <- 0.5

yhat2 <- as.numeric(phat > thresh2)

data.frame(predicted = yhat2, observed = y) %>%
  xtabs(~ predicted + observed, data = .)

# threshold 3 (0.75)
thresh3 <- 0.75

yhat3 <- as.numeric(phat > thresh1)

data.frame(predicted = yhat3, observed = y) %>%
  xtabs(~ predicted + observed, data = .)

```

Response: 


## 4. ROC curve

__Construct an ROC curve for the model. Display the ROC curve below and comment on what you see.__

```{r}
# make roc curve
# remember that the roc_curve function from the pROC function needs the observed outcomes and the predicted probabilities from the model
roc_curve <- roc(response = y, predictor = phat)

# plot
plot(roc_curve, main = "ROC Curve for CHD", col = "blue")
#ggroc(roc_curve)

```

What do you see?

## 5. AUC 

__Calculate the area under the ROC curve (AUC). Interpret this value in the context of how cases tend to be ranked by the model compared to controls.__

```{r}
# print the auc value
auc(roc_curve)

```

Interpretation:

## 6. Shrinkage methods

__We're worried we may have overfit in the model above. Fit a cross-validated lasso logistic regression model to help account for possible overfitting. Use AUC as the metric of model fit. What happens to the AUC compared to the AUC calculated in part 11? Why do you think that is?__

```{r}
# cross-validation randomly splits the data, so setting the seed helps make sure you always get the same results (reproducibility)
set.seed(1234)



# using AUC as the measure of fit
# reminder: to change the metric used, set type.measure to the metric you want (auc, deviance, etc.) 
# lasso

# show output 

```


Interpretation: 

## 7. Which variables were kept?

__If we wanted to choose the biggest lambda penalty value that gives us an AUC within 1 standard error of the best AUC using the lasso method (lambda.1se), which covariates are kept in the model? Is race kept in the model?  Is this consistent with what we saw in part 2?__ 

```{r}
# grab coefficients
# reminder, you can use coef(name_of_model, "lambda.1se")




```

Interpretation: 


## 8. Lasso with deviance

__Fit the lasso model again, but this time use deviance as the model fit metric. Compare the coefficients left in this model (again using "lambda.1se") to the model using AUC to choose the best fitting model. What do you notice? Which method (metric) of choosing a model would you want to use if your main goal was classification?__

```{r}
# lasso with deviance


# compare covariates kept in the model

```


## 9. Propensity Score Model

__Now suppose we're more interested in statistical inference than prediction. Fit a propensity score model for race as the outcome using the remaining predictors from the model above. Which variables are related to race in the adjusted model?__

```{r}

# fit the propensity score model


# show model output


```

Response: 

## 10. Adjusting for propensity scores

__Calculate the propensity scores using the model above. Use the propensity scores as a predictor, along with race, in a model for self-reported hot flashes. Interpret the coefficients in the model.__

*Note: you can save the propensity scores form the model above as a new column in the data to use in the regression model*

```{r}

# calculate and save propensity scores


# fit model


# print output


```

Interpretation: 


## 11. Check Linearity

__Check the linearity condition (visually) for this model. Does it look like the linearity assumption holds?__

```{r}

# check linearity condition


```

Interpretation: 

## 12. Propensity Score Quintiles

__Break the propensity scores into quintiles (5 groups of roughly equal size) and use this as a categorical predictor of self-reported hot flashes in addition to race. Interpret the coefficients in this model.__

```{r}
# split propensity scores into quintiles
# To cute the data into quintiles we can use the cut() function
# with breaks = quantile(your_propensity_scores, probs = (0:5)/5)
# make sure to use argument include.lowest = T





# fit model


# print output


```

Interpretation: 

## 13.  Linearity Condition

__Do we need to check the linearity in the model above (using quintiles)? Why or why not? If yes, check the linearity condition (visually).__

```{r}
# if yes, check linearity condition

```

Answer: 


## 14. Compare Models

__Which model do you prefer of the four we've fit? The simple logistic regression model with just race, the multiple logistic regression adjusting for all covariates separately, the model adjusting for race and propensity score as a numeric variable, or the model adjusting for race and propensity score quintiles? Why?__

```{r}

# feel free to check more model metrics here



```

Response here:








## 15. Summary

__Summarize your findings. Was race associated with hot flashes? What about when other covariates were adjusted for? Did the model do a good job classifying those with and without hot flashes?__





```{r}

sessionInfo()

```



