---
title: "M6 Lab"
author: "Matthew Pr√¶stgaard"
date: "Spring 2024"
output:
  rmdformats::downcute:
    self_contained: true
    default_style: "dark"
    downcute_theme: "default"
    code_folding: "show"
  svglite:
    fig.retina: 2
---

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
```


# Lab Setup

### Note: some results may not show up properly in the defauly (dark) theme

## R packages

Load necessary packages. 

```{r, message = FALSE}
library(tidyverse)
library(here)
library(MASS)
library(pscl)
library(lmtest)
library(car)
library(ggpubr)
library(kableExtra)
library(ggthemr)
ggthemr("flat dark")
library(plotly)
library(jtools)
library(ggh4x)
library(broom)

source(here("Functions", "ggHist2.r"))
source(here("Functions", "summariseVar.r"))
source(here("Functions", "ggResid.r"))
```

## Data management

The data were obtained from a survey that was aimed to investigate the factors associated with the number of physician office visits over the past two years.
The surveys contain interview from 2,500 people in the United States. They include demographics, health condition, and insurance information of each interviewee.



```{r, message = FALSE}
# read in data
data <- read_csv(here("Lab6", "hw6.csv")) %>%
  drop_na() %>%
  mutate(
    healthStat = factor(health - 1)
  )
# turn health status into a factor variable so it doesn't get treated as a numeric 1, 2, 3
```


## 1. Visualize Data

__Generate a histogram of the outcome variable and comment on the shape. Summarize the outcome variable using summary statistics.__
__Based on these two analyses, is linear regression appropriate? What type of regression do you think is necessary to answer the remaining questions? Why?__

```{r, message = FALSE}
# histogram of outcome
histVisit <- ggHist2(data, visit, bins = 35, title = "Histogram of Number of Visits")
ggplotly(histVisit)

# summary statistics
sumVisit <- summarize.var(data, visit)
kable(sumVisit)
```

Side note: it would be great if ggplot/tidyverse/Posit would stop always changing their notation guidelines/standards and preferred arguments every 3 months so that
I don't have to see a warning about something benign all the time

Description: The data are heavily right-skewed, as seen in the histogram, and have a standard deviation higher than the mean.
Since we are dealing with counts as our outcome variable, linear regression is not appropriate. A Poisson or negative binomial model would be appropriate instead.
The high variance (52.62) suggests that negative binomial regression is the more appropriate of the two.

## 2. Poisson model

__Fit a Poisson model that estimates the expected number of physician office visits adjusting for health status, sex, race, condition of limiting activities of living,__
__race, private insurance information, age, chronic conditions, and education. Show the output and interpret the coefficient for the chronic conditions variable.__
__Which variables appear to be associated with the outcome?__

```{r}
# Poisson model
# glm(y ~ x1 + x2 + ..., data = data_name, family = poisson(link = "log"))
visitPois <- glm(visit ~ healthStat + sex + race + adldiff + privins + age + cond + edu, data = data, family = poisson(link = "log"))

# show model output
summ(visitPois)
summary(visitPois)

kable(exp(coef(visitPois)))
```

Interpretation: All of the variables appear to be associated with the outcome.
For each additional chronic condition an individual has, the expected log count of visits increases by 0.14 (visits increase by 1.15).


## 3. Model Assumptions

__Evaluate the fit of this model. Are the assumptions for Poisson model met?__

```{r}
# evaluate model assumptions
Deviance <- deviance(visitPois)
X2Pois <- sum(resid(visitPois, type = "pearson")^2)
df <- visitPois$df.residual

kable(vif(visitPois))

influenceIndexPlot(visitPois, c("Cook", "student", "hat"))

Deviance / df
X2Pois / df

pchisq(Deviance, df = visitPois$df.residual, lower.tail = FALSE)
pchisq(X2Pois, df = visitPois$df.residual, lower.tail = FALSE)
```

Interpretation: The assumptions for Poisson regression are not met. The largest violation that stands out is the discrepency 
between the mean and the variance, which are vastly different. This is also shown in our calculated 
ùúô values. In addition, the diagnostic plots show a number of highly influential, potentially problematic points.


## 4. Consequences of unmet assumptions

__What are some of the consequences of overdispersion in a Poisson model? That is, if there is overdispersion in__
__the model that isn't accounted for, what can go wrong? What are some ways we can account for overdispersion to make our conclusions more valid?__


Response: Overdispersion in our model can lead to standard errors different from the true values, 
reducing our ability for inference based on the model.
This can be remedied by either adjusting the standard errors or by using a different model

```{r}
quasiPois <- glm(visit ~ healthStat + sex + race + adldiff + privins + age + cond + edu, data = data, family = quasipoisson(link = "log"))
summ(quasiPois)

sink("quasiPois.txt")
summary(quasiPois)
sink()
```

As is seen, using a quasipoisson model leads to larger standard errors than the unadjusted model.

## 5. Negative Binomial Model

__Fit a negative binomial regression model using the same variables as the Poisson model above. Show the model output.__
__Are there any differences between the trends found in this model and the trends found in the Poisson model in part 2? Why do you think that is?__

```{r}
# fit negative binomial model
# from the MASS package: glm.nb(y ~ x1 + x2 + ...., data = data_name)
visitNB <- MASS::glm.nb(visit ~ healthStat + sex + race + adldiff + privins + age + cond + edu, data = data)

# show model output
summ(visitNB)

# saving to text file for reference
sink("visitNB.txt")
summary(visitNB)
sink()
```

Response: The standard errors of the negative-binomial model are larger than those of the poisson model. The point
estimates are roughly the same.

## 6. LRT

__Run a likelihood ratio test to compare the Poisson and negative binomial models. What does this test tell us?__

```{r}
# likelihood ratio test
odTest(visitNB)
```

Response: With a test statistic of **ùõò¬≤=6610.399** and **p=2.2e-16**, we can conclude that the poisson model is not
appropriate to use and that **ùúÉ ‚â† 0**.

## 7. Model fit metrics

__Compare the Poisson and negative binomial models using other metrics of model fit (e.g. log-likelihood, deviance, AIC, BIC, pseudo R^2). You don't have to do all of these, but check a few. Pick the model you think is best.__

```{r}
AIC1 <- AIC(visitPois)
BIC1 <- BIC(visitPois)

AIC2 <- AIC(visitNB)
BIC2 <- BIC(visitNB)
Deviance2 <- deviance(visitNB)

diagPois <- tibble(AIC1, BIC1, Deviance)
kable(diagPois, caption = "Diagnostic Values of Poisson Model")

diagNB <- tibble(AIC2, BIC2, Deviance2)
kable(diagNB, caption = "Diagnostic Values of Negative-Binomial Model")

ggResid(visitPois, title = "Residuals vs Fitted Values (Poisson)") %>%
  ggplotly()
ggResid(visitNB, title = "Residuals vs Fitted Values (Negative-Binomial)") %>%
  ggplotly()
```

## 8. Difference in log expected count

__Using the model you picked, how much higher would the log of the expected number of visits be for someone with 1 chronic health condition compared to someone with none?__


```{r}
# you can do this by hand using the coefficients printed out by summary
# you can also grab the coefficients from the model using model_name$coefficients and manipulating this vector the get the values you want
```

$$\log(\text{Expected Count}) = \beta_0 + \beta_1 \times \text{cond}$$
$$\log(\text{Expected Count}) = 2.1502 + 0.1586 \times \text{cond}$$
$$\log(\text{Expected Count}_{\text{cond}=1}) - \log(\text{Expected Count}_{\text{cond}=0}) = \beta_1 \times (1 - 0)$$
$$\log(\text{Expected Count}_{\text{cond}=1}) - \log(\text{Expected Count}_{\text{cond}=0}) = 0.1586 \times 1$$


As the coefficient for health conditions in the NB model is 0.159, someone with one chronic health condition would
have a log expected number of visits **0.159** higher than someone with none, holding all else equal.

## 9. Expected count

__Exponentiate the number you got in part 8 and interpret this value in terms of the expected number of of visits comparing the person with 1 chronic condition to the person with no chronic conditions.__

```{r}
exp(0.158599)
```

Interpretation: Someone with one health condition would have **1.17** more expected visits compared to someone with none,
holding all else equal.

## 10. Modling effect modification

__Using the model you picked above, add an interaction term between private insurance and chronic conditions.__
__Using the model outcome, calculate the same comparisons as in parts 8 and 9 for people with insurance and for people without insurance.__
__Interpret the coefficients for chronic conditions, private insurance, and their interaction in this model.__

```{r}
# model with interaction
NBInter <- glm.nb(visit ~ healthStat + sex + race + adldiff + privins * cond + age + edu, data = data)
# show output
summ(NBInter)

sink("NBInter.txt")
summary(NBInter)
sink()

exp(coef(NBInter))
```

**Chronic Conditions**:  For individuals without private insurance, each additional chronic condition is 
associated with a ~16.3% increase in the expected count of physician visits (0.159 log visits), holding all other variables constant.  
**Private Insurance**: -0.205 For individuals without chronic conditions, having private insurance is associated with
a ~18.5% decrease in expected visits (-0.205 log visits), holding all else constant.  
**Interaction Term**: 0.034 For those with private insurance, every additional chronic condition increases the number
of expected office visits by ~20.1% (0.151 + 0.034 log visits), compared to the 16.3% increase for those without,
holding all else constant.  
The p-value for the interaction term (0.282) suggests that this effect is not significant.

## 11. Testing for Effect modification

__Test if the association between chronic conditions and number of visits is modified by private insurance status (using the mode fit in part 10). Interpret the results of this test.__


```{r}
# likelihood ratio test
anova(visitNB, NBInter)
```

Interpretation: With **p=0.291**, we do not have evidence at the 0.05 significance level to support that private insurance status modifies
the relationship between the number of chronic conditions and the expected count of physician visits. 

## 12. Checking model fit

__Assess the model fit from the model you picked. Are there any problematic points that you're worried about?__

```{r}
# check model fit/problematic points
AIC3 <- AIC(NBInter)
BIC3 <- BIC(NBInter)
Deviance3 <- deviance(NBInter)
R2Int <- pR2(NBInter)

diagNBInt <- tibble(AIC3, BIC3, Deviance3, NBInter)
kable(diagNBInter, caption = "Diagnostic Values of Interaction Term Negative-Binomial Model")

influenceIndexPlot(NBInter, c("Cook", "student", "hat"))
```

Interpretation: There are some points that are of concern. In the Cook's Distance plot, a couple points are drastically higher than the rest (477 and 1284), suggesting
these points are highly influential. There are a couple points which have much higher hat-values than the rest, suggesting that they are very high leverage and potentially
influential.

## 13. Unequal follow-up

__Suppose that instead of asking people how many times they had visited a physicians office in the past two years, ran a cohort study to track the__
__number of physician office visits per person, but people are followed for unequal periods of time (some people get enrolled later, some people move, etc.).__
__How could we have handled this variability in follow-up time across patients in our regression models?__ 

Response: This variability could be accounted for by modelings instead of counts. It could also be accounted for by using an offset of person-time in the model.

## 14. Zero-Inflation

__Are you concerned at all about zero-inflation in the model you chose? Why or why not?__

```{r}
# checking for zero-inflation
performance::check_zeroinflation(NBInter)
performance::check_zeroinflation(visitNB)
```

Response: Based on the ratio of predicted to observed of **1.50** in the interaction model and **1.49** in the simple model, there is concern for zero-inflation.

## 15. Summary

__Summarize your findings.__

Summary: In this lab, we intended to see if there is a correlation between the expected number of physician office visits and multiple predictors.
A poisson model was originally fit, with all covariates being found to be statistically significantly associated with the outcome. This model did not
meet the assumptions for a poisson model, however, so a negative binomial model was used instead. Sex and race were not statistically significantly associated in this.
A likelyhood ratio test further suggested that a poisson model was not appropriate to use. Smaller AIC and BIC values in the negative binomial model further suggest
being more appropriate. Influential and high-leverage points were tested for and discovered, potentially reducing how accurate our model is.
An interaction term of private insurance and number of chronic conditions was added, but this was found to not be statistically significant.
The interaction and non-interaction models both showed zero-inflation.





```{r}
sessionInfo()
```


